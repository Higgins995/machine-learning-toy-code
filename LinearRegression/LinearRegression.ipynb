{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('py37': conda)"
  },
  "interpreter": {
   "hash": "fbea1422c2cf61ed9c0cfc03f38f71cc9083cc288606edc4170b5309b352ce27"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 一元线性回归\n",
    "\n",
    "以一元为例，$y=w_1x_1+b=w^Tb=w_1x_1+w_0x_0$, 实际使用梯度下降法时可以令$x_0=1$,则求出的$w_0=b$\n",
    "\n",
    "### 梯度下降法\n",
    "\n",
    "如何求取梯度？\n",
    "\n",
    "给定模型$h(\\theta)=\\sum_{j=0}^{n} \\theta_{j} x_{j}$以及目标函数(损失函数):$J(\\theta)=\\frac{1}{m} \\sum_{i=0}^{m}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right)^{2}$, 其中$m$表示数据的量，我们目标是为了$J(\\theta)$尽可能小，所以这里加上$\\frac{1}{2}$为了后面的简化，即$J(\\theta)=\\frac{1}{2m} \\sum_{i=0}^{m}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right)^{2}$。  \n",
    "那么梯度则为：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_{j}} &=-\\frac{1}{m} \\sum_{i=0}^{m}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right) \\frac{\\partial}{\\partial \\theta_{j}}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right) \\\\\n",
    "&=-\\frac{1}{m} \\sum_{i=0}^{m}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right) \\frac{\\partial}{\\partial \\theta_{j}}\\left(\\sum_{j=0}^{n} \\theta_{j} x_{j}^{i}-y^{i}\\right) \\\\\n",
    "&=-\\frac{1}{m} \\sum_{i=0}^{m}\\left(y^{i}-h_{\\theta}\\left(x^{i}\\right)\\right) x_{j}^{i}\\\\\n",
    "&=\\frac{1}{m} \\sum_{i=0}^{m}\\left(h_{\\theta}-y^{i}\\left(x^{i}\\right)\\right) x_{j}^{i}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "设$x$是(m,n)维的矩阵，$y$是(m,1)维度的矩阵，$h_{\\theta}$是预测的值，维度与$y$相同，那么梯度用矩阵表示如下:\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_{j}} = \\frac{1}{m}x^{T}(h_{\\theta}-y)\n",
    "$$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def true_fun(X):\n",
    "    return 1.5*X + 0.2\n",
    "\n",
    "np.random.seed(0) # 随机种子\n",
    "n_samples = 30\n",
    "'''生成随机数据作为训练集'''\n",
    "train_X = np.sort(np.random.rand(n_samples)) \n",
    "train_y = (true_fun(train_X) + np.random.randn(n_samples) * 0.05).reshape(n_samples,1)\n",
    "data_X = []\n",
    "for x in train_X:\n",
    "    data_X.append([1,x])\n",
    "data_X = np.array((data_X))\n",
    "m,n = np.shape(data_X) # m, 数据量 n: 特征数\n",
    "print(m)\n",
    "maxiter = 1000 # 迭代数\n",
    "weights = np.ones((n,1))  \n",
    "alpha = 0.1 # 学习率\n",
    "for i in range(0,maxiter):\n",
    "    error = np.dot(data_X,weights)- train_y\n",
    "    gradient = data_X.transpose().dot(error)/m\n",
    "    weights = weights - alpha * gradient\n",
    "print(\"输出参数w:\",weights[1:]) # 输出模型参数w\n",
    "print(\"输出参数:b\",weights[0]) # 输出参数b\n",
    "\n",
    "\n",
    "test_X = np.linspace(0, 1, 100)\n",
    "plt.plot(test_X, test_X*weights[1][0]+weights[0][0], label=\"Model\") \n",
    "plt.plot(test_X, true_fun(test_X), label=\"True function\")\n",
    "plt.scatter(train_X,train_y) # 画出训练集的点\n",
    "plt.legend(loc=\"best\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## scikit-learn\n",
    "scikit-learn，简称sklearn，是一个开源的基于python语言的机器学习工具包。它通过NumPy, SciPy和Matplotlib等python数值计算的库实现高效的算法应用，并且涵盖了几乎所有主流机器学习算法。\n",
    "\n",
    "官网：https://scikit-learn.org/stable/index.html"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression # 导入线性回归模型\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def true_fun(X):\n",
    "    return 1.5*X + 0.2\n",
    "\n",
    "np.random.seed(0) # 随机种子\n",
    "n_samples = 30\n",
    "'''生成随机数据作为训练集'''\n",
    "train_X = np.sort(np.random.rand(n_samples)) \n",
    "train_y = true_fun(train_X) + np.random.randn(n_samples) * 0.05\n",
    "\n",
    "model = LinearRegression() # 定义模型\n",
    "model.fit(train_X[:,np.newaxis], train_y) # 训练模型\n",
    "\n",
    "print(\"输出参数w:\",model.coef_) # 输出模型参数w\n",
    "print(\"输出参数:b\",model.intercept_) # 输出参数b\n",
    "\n",
    "test_X = np.linspace(0, 1, 100)\n",
    "plt.plot(test_X, model.predict(test_X[:, np.newaxis]), label=\"Model\")\n",
    "plt.plot(test_X, true_fun(test_X), label=\"True function\")\n",
    "plt.scatter(train_X,train_y) # 画出训练集的点\n",
    "plt.legend(loc=\"best\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 多元线性回归\n",
    "\n",
    "以三元为例，$y=w_1x_1+w_2x_2+w_3x_3+b=w^Tb$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = [[1,1,1],[1,1,2],[1,2,1]]\n",
    "y = [[6],[9],[8]]\n",
    " \n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "print(\"输出参数w:\",model.coef_) # 输出参数w1,w2,w3\n",
    "print(\"输出参数b:\",model.intercept_) # 输出参数b\n",
    "test_X = [[1,3,5]]\n",
    "pred_y = model.predict(test_X)\n",
    "print(\"预测结果:\",pred_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 多项式回归以及过拟合与欠拟合"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 训练集\n",
    "用来训练模型内参数的数据集\n",
    "\n",
    "### 验证集\n",
    "用于在训练过程中检验模型的状态，收敛情况，通常用于调整超参数，根据几组模型验证集上的表现决定哪组超参数拥有最好的性能。\n",
    "\n",
    "同时验证集在训练过程中还可以用来监控模型是否发生过拟合，一般来说验证集表现稳定后，若继续训练，训练集表现还会继续上升，但是验证集会出现不升反降的情况，这样一般就发生了过拟合。所以验证集也用来判断何时停止训练\n",
    "\n",
    "### 测试集\n",
    "测试集用来评价模型泛化能力，即使用训练集调整了参数，之前模型使用验证集确定了超参数，最后使用一个不同的数据集来检查模型。\n",
    "\n",
    "### 交叉验证\n",
    "\n",
    "交叉验证法的作用就是尝试利用不同的训练集/测试集划分来对模型做多组不同的训练/测试，来应对测试结果过于片面以及训练数据不足的问题。\n",
    "\n",
    "![jupyter](./cross_valid.png)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "degrees = [1, 4, 15] # 多项式最高次\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples)) \n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)]) # 使用pipline串联模型\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # 使用交叉验证\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    print(\"socres\", scores)\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
    "        degrees[i], -scores.mean(), scores.std()))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}